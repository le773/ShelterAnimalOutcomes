# ShelterAnimalOutcomes

在文章的末尾，我想分享两个重要的思想： 
1. 仅仅靠参数的调整和模型的小幅优化，想要让模型的表现有个大幅度提升是不可能的。GBM的最高得分是0.8487，XGBoost的最高得分是0.8494。确实是有一定的提升，但是没有达到质的飞跃。 
2. 要想让模型的表现有一个质的飞跃，需要依靠其他的手段，诸如，特征工程(feature egineering) ，模型组合(ensemble of model),以及堆叠(stacking)等。


数据来自:[shelter-animal-outcomes](https://www.kaggle.com/c/shelter-animal-outcomes)

代码思想来自:[机器学习系列(12)_XGBoost参数调优完全指南](https://blog.csdn.net/han_xiaoyang/article/details/52665396)
